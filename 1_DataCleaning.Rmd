---
title: "Introduction to Animal Movement Analyses"
author: "Jared Stabach, Smithsonian's National Zoo & Conservation Biology Institute"
date: '`r format(Sys.time(), "%d %B %Y")`'
output:
  html_document:
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: true
      smooth_scroll: true
    number_sections: false
    #theme: united
    #highlight: tango
pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<a href="https://github.com/Smithsonian/Wildebeest_HMM.git" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

# Introduction
  >Example: White-bearded wildebeest (2010-2013)
  
We will use a dataset collected during my PhD field research for all future exercises in this course.  The dataset consists of 36 adult white-bearded wildebeest (*Connochaetes taurinus*) fitted with Lotek WildCell^TM^ GPS tracking devices that were tracked across three separate ecosystems (Amboseli Basin, Athi-Kaputiei Plains, and the Greater Maasai Mara) in southern Kenya from 2010-2013.  These data are freely available on [Movebank](https://www.movebank.org/).  Known to be particularly important to ecosystem function and diversity, many resident populations of wildebeest have become threatened with extinction over the past few decades.  The goal of this research was to understand how natural and anthropogenic change were affecting the movements of wildebeest fitted with tracking devices.

<div style="float:right">
<img width="270" height="176" src="DSC_0287.jpg">
</div>

These data can be referenced as:

Stabach JA, Hughey LF, Crego RD, Fleming CH, Hopcraft JGC, Leimgruber P, Morrison TA, Ogutu JO, Reid RS, Worden JS, Boone RB. 2022. Increasing anthropogenic disturbance restricts wildebeest movement across East African grazing systems. Frontiers in Ecology and Evolution. [doi.org/10.3389/fevo.2022.846171](https://doi.org/10.3389/fevo.2022.846171)

Stabach JA, Hughey LF, Reid RS, Worden JS, Leimgruber P, Boone RB. 2020. Data from: Comparison of movement strategies of three populations of white-bearded wildebeest. Movebank Data Repository. [doi:10.5441/001/1.h0t27719](https://www.datarepository.movebank.org/handle/10255/move.1095)

In this excercise and those that follow, you will:

  * Import and clean an animal movement trajectory
  * Visualize the data and provide summary plots of the animal movements
  * Learn the analysis workflow for fitting Hidden Markov Models (HMMs) with `moveHMM`
  
# Data Preparation
In previous exercises, we analyzed data as a continuous-space, continuous-time stochastic process.  Here, we will analyze data in discrete time to identify changes in animal behavior.  

As a first step, we must first clean the data received before taking any additional steps. This includes filtering the dataset for completeness, identifying duplicate records, removing invalid start or stop dates, identifying positions of poor data quality, and ordering the dataset sequentially so that we can import the data into `moveHMM` for analyses.  Nearly all manufacturers report some type of positional quality, often reported as the type of position (e.g., 1D, 2D, or 3D) or Dilution of Position (DOP - horizontal or vertical).  Large DOPs indicate poor positional quality that can be filtered from the dataset.

## Load Libraries
Load the required libraries and remove everything held in [R's](https://cran.r-project.org/) memory.

```{r Clean Libraries, message=FALSE, warning=FALSE}
# Remove from memory
rm(list=ls())

# You may need to install these packages first
#install.packages('svDialogs', 'tidyverse', 'move2', 'lubridate')

# Load required libraries
library(svDialogs)
library(tidyverse)
library(move)
library(lubridate)
library(tmap)

#library(sf)
#library(amt)
#library(adehabitatLT)

#library(gt)
#library(cowplot)
#library(suncalc)
```

## Set Time Zone & Coordinate System
I prefer to keep items that require user input to appear at the top of my scripts.  For me, this is helpful when transitioning between different studies because most of the introductory code is essentially the same, except for the time zone and local projection used.  I recommend importing your data in UTC time with geographic (Lat/Long) coordinates and then converting these values to your local time zone and coordinate system.

In this example, we will update UTC (Coordinated Universal Time) to East Africa Time (EAT) since our data were collected in Kenya.  See the [wiki](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones) for your appropriate timezone identifier. We will also project all geographic data to Universe Tranverse Mercator (UTM) zone 37 south. The unit of measurement of this coordinate system is meters, advantageous to calculate understandable distances between points. 

Identifying the correct UTM zones is relatively simple, with multiple options:

  1. Mathematical Approach
      + Take a longitudinal coordinate (or calculate the mean value) from your dataset and add 180.  Then divide by 6 and round up to the nearest whole number.
      + Example: -39 + 180 = 141 / 6 = 23.5 == 24
      + 39$^\circ$W is UTM zone 24.  Then simply determine if the point is above (N) or below (S) the equator.
  
  2. Check the PRJ File
      + Check the .prj file with an associated shapefile of your study area.   

  3. Download the World UTM Grid
      + ArcGIS (or similar GIS software) include downloadable [UTM Zones](https://hub.arcgis.com/datasets/esri::world-utm-grid/explore) data layers.  Loading this file with your point dataset will show you where your data overlap.

  4. Check the Zone Number in Google Earth (might be difficult in China)
      + Convert your dataset to a KMZ/KML file and load into Google Earth.  Be sure your units are set to UTMs in Google Earth.  The zone number will appear at the bottom center of your screen when you zoom into your file.
  
**NOTE**: The data we are using spans multiple UTM zones (UTM 36 south and UTM 37 south).  In this case, it isn't a problem because we will be subsetting our data and only using data that overlap with UTM 37 south.  Other coordinator systems, such as Lambert or Albers Equal-Area conic projections, could be used for datasets that span multiple UTM zones, minimizing distortion.  It's important to correctly input the parameters of your selected coordinate system.

```{r Clean Timezone}
# Set TimeZone and UTM Zone
# Other timezones can be found at: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
Timezone1 <- 'UTC'
Timezone2 <- "Africa/Nairobi"
 
# UTM Zone
LatLong.proj <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"  # EPSG:4326
UTMZone.proj <- "+proj=utm +zone=37 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs" #+inits=EPSG:32737"
#UTMZone.proj <- "+inits=EPSG:32737"
```

## Load Collar Data
All data are available via [Movebank](https://www.movebank.org/).  These data have already been downloaded and are available in your `/Data` folder as a `.csv`. Included is a reference file (also downloaded from [Movebank](https://www.movebank.org/)), which contains additional details (sex, age) about each animal.  

Most important is that any movement dataset included in analysis has the following variables:

1) Unique Animal ID
2) Time stamp
3) Coordinates (X/Y)

**NOTE**: If you open the file provided in Excel, do **NOT** save the file before loading it in [R](https://cran.r-project.org/). Excel will change the time stamp column and set it to the time on your computer - obviously not what you want for most studies.

```{r Load, message=FALSE, warning=FALSE}
# We can upload each file directly and convert to a dataframe 
#WB <- as.data.frame(read_csv("./Data/White-bearded wildebeest (Connochaetes taurinus) movements - Kenya.csv"))

# Or list the files so we don't have to type so much
# Create list
lf <- list.files(path="./Data/", pattern = '.csv', all.files=FALSE, full.names=TRUE)
lf

WB <- as.data.frame(read_csv(lf[2]))
WB.ref <- as.data.frame(read_csv(lf[1]))

# Look at the data
# head(WB)
# head(WB.ref)

# Fix a few column name issues
names(WB) <- gsub("-", "_", names(WB))
names(WB) <- gsub(":", "_", names(WB))
names(WB.ref) <- gsub("-", "_", names(WB.ref))

# Check to identify the changes
# head(WB)
# head(WB.ref)

# We could also pull the file directory from Movebank.  To do so, you will need a Movebank UserName and Password.
# This is particularly useful when data continue to be collected (i.e., are actively streaming) on a study.
# Note: When pulling from Movebank, the data will contain a few more data fields than the uploaded CSV

# Set Movebank Login Details
# UN <- dlgInput("Enter Movebank UserName: ", Sys.info()[""])$res
# PW <- dlgInput("Enter Movebank Password: ", Sys.info()[""])$res

# Details
# login <- movebankLogin(username=UN, password=PW)
 
# Pull Data from Movebank and convert to a dataframe
# WB <- as.data.frame(getMovebankData(study = "White-bearded wildebeest (Connochaetes taurinus) movements - Kenya", login = login))
 
# Reference Data - No need to import here, as data are already subset in Movebank
# WB.ref <- getMovebankReferenceTable(study = "White-bearded wildebeest (Connochaetes taurinus) movements - Kenya", login = login)
```

## Dataframe Verification
It's always good practice to look at your data and make sure the dataset has uploaded correctly.  We should have `r length(unique(WB$tag_local_identifer))` animals across `r length(unique(WB.ref$study_site))` distinct ecosystems.  The timezone should be UTC. We can also use some simple commands to summarize the dataset, including:

* `head()` to view the first few lines of the data object
* `tail()` to view the last few lines of the data object
* `dim()` to print the dimensions of the data object (i.e., rows and columns)
* `str()` to provide the structure of the data object

**Question 1: **How would you change the code to view the last few lines of the dataset?  What would you do to view the first 10 rows?
```{r Verify, message=FALSE, warning=FALSE, results='hide', echo=TRUE}
head(WB)
```

**Question 2: **What tags are included in the study?  How many?
```{r Verify2, message=FALSE, warning=FALSE, results='hide', echo=TRUE}
sort(unique(WB$tag_local_identifier))
length(unique(WB$tag_local_identifier))
```

**Question 3: **How many study areas are included in the dataset?  What are the study area names?
```{r Verify3, message=FALSE, warning=FALSE, results='hide', echo=TRUE}
length(unique(WB.ref$study_site))
unique(WB.ref$study_site)
```

**Question 4: **What is the structure of the dataset?  What is the data type of the timestamp column?
```{r Verify4, message=FALSE, warning=FALSE, results='hide', echo=TRUE}
str(WB)
str(WB.ref)
```

**Question 5: **How many rows and columns are there in the movement dataset?
```{r Verify5, message=FALSE, warning=FALSE, results='hide', echo=TRUE}
dim(WB)
nrow(WB)
ncol(WB)
```

**Question 6: **What is the timezone of the dataset?
```{r Verify6, message=FALSE, warning=FALSE, results='hide', echo=TRUE}
tz(WB$timestamp)
```

## Dataframe Organization & Cleaning
Many of the columns included in the dataframes are unnecessary (and quite long).  We need to clean and filter each dataframe and can do so with tools from the [tidyverse](https://cran.r-project.org/web/packages/tidyverse/index.html) package.  Here, we will update the timezone to the local time zone and subset the start/end dates for each animal to match with what we recorded in our reference dataset.  These dates represent the dates that the collar was deployed on the animal.  To do so we need to join the two dataframes together using a shared primary key (i.e., id). Lastly, we will check on the completeness of the dataset and filter out erroneous data points.

**NOTE**: date/time fields can often present issues and be difficult to import.  If problems exist, you may need to properly format the date/time fields first.  See the [lubridate](https://cran.r-project.org/web/packages/lubridate/index.html)) package for some instructions and/or the [strptime](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/strptime) package to format your date/time field. Note the format of **YOUR** own dataset (e.g., "%Y-%m-%d %H:%M:%S").  Also note that some manufacturers put the date and time in separate columns.  You'll need to put these columns together to create a timestamp.  For example, `timestamp = ymd_hms(paste(date,time),tz = 'Africa/Nairobi')`

```{r Clean Merge}
# Clean the reference file, selecting only the columns that you want to include
# Important is that the file contains the deployment on and off date and times. These dates will allow us to filter/remove datapoints outside of the deployment window
# Using the pipe (%>%) operator here to join a series of commands together

WB <- WB %>%

  # Pull in the WB.ref dataset to join the study site column
  left_join(WB.ref, by = join_by("tag_local_identifier" == "tag_id")) %>%

  # Rename columns and create local timestamp - UTC to local
  # Select only columns of interest
  transmute(id = tag_local_identifier,
            animal_id = individual_local_identifier,
            latitude = location_lat,
            longitude = location_long,
            sex = animal_sex,
            DOP = gps_dop,
            fixType = gps_fix_type_raw,
            temp = external_temperature,
            timestamp = with_tz(timestamp, tz=Timezone2),
            deploy_on = with_tz(deploy_on_date, tz=Timezone2),
            deploy_off = with_tz(deploy_off_date, tz=Timezone2),
            study_site = study_site) %>%

  # Correct the data type for specific fields
  mutate(across(c(id,sex,study_site), as.factor)) %>%

  # Make sure no duplicate id and timestamp exist.
  distinct(animal_id, timestamp, .keep_all = TRUE) %>%

  # Remove any records that don't have a timestamp or a Lat/Long location
  filter(!is.na(timestamp),
         !is.na(latitude),
         !is.na(longitude),
         latitude != 0,
         longitude != 0,

         # Grab only the Athi-Kaputiei Data
         study_site == "Athi-Kaputiei Plains",

         # And use the deploy on and off dates to further subset
         # (Won't do anything here, as dates already subset)
         timestamp >= deploy_on & timestamp <= deploy_off) %>%

  # Remove fields that are now unnecessary.  Dropping the deployment dates and the study area
  dplyr::select(-c(deploy_on, deploy_off, study_site)) %>%
  
  # Remove extra levels (important since subsetting to a single study area)
  # The droplevels function re-assess what levels are in the data and drops the rest
  droplevels() %>%

  # Arrange the dataset by id and timestamp
  arrange(id, timestamp)

# Look again (yes again!) at your data
head(WB)
str(WB)

# What tags are included in the study now?  How many?
sort(unique(WB$id))
length(unique(WB$id))
```

# Visualize

Text here

```{r}
# # Create sf object
# WB.sf <- WB %>% 
#   st_as_sf(coords = c('longitude', 'latitude'),
#            crs = LatLong.proj) %>% 
#   st_transform(UTMZone.proj)
# 
# # Plot the data
# plot(WB.sf["animal_id"], 
#      main = paste0("Wildebeest: Athi-Kaputiei Plains (n = ", length(unique(WB.sf$id)),")"))
# 
# # We can do better than that, but at least this confirms what I'd expect
# WB.sf %>% 
#   ggplot() +
#   geom_sf(aes(fill = animal_id),
#           alpha = 0.6,
#           shape = 21,
#           col = "black") +
#   theme_bw()
# 
# # or separate each individual into its own plot
# WB.sf %>% 
#   ggplot() +
#   geom_sf(aes(fill = animal_id),
#           alpha = 0.6,
#           shape = 21,
#           col = "black") +
#   theme_minimal() +
#   facet_wrap(~ animal_id)

# This is perhaps the most helpful view for getting a sense of the data collected for each individual, how much their space use varies, and whether there are errant points that may represent actual GPS error. Here fortunately there are no points that can be identified visually as significant outliers. Be sure to use the "zoom" button above the plot to see it in larger size.

# Let's do the same thing using tmap, overlaying the data on a satellite map to investigate potential problems
# tmap camps can be made in "view" or "interactive" mode, or "plot" mode.  Plot mode is better for making stating maps

# tmap_mode("view")
# 
# # Here we can select a range of basemaps. And you can find a list of available maps HERE. 
# # https://leaflet-extras.github.io/leaflet-providers/preview/
# 
# # You can also type "providers$" in the console to see all the options, but this won't allow you to easily preview them.
# 
# # Here I'm pulling a world satellite map, and a world street map. 
# # Note also that in tmap we need to refer to our variables in quotes.
# 
# tm_basemap(c("Esri.WorldImagery",
#              "OpenStreetMap.HOT")) +
#   tm_shape(WB.sf, 
#            name = "Wildebeest Locations (Athi-Kaputiei)") +
#   tm_dots(size = 0.05,
#           title = "Wildebeest ID",
#           col = "animal_id",
#           alpha = 0.5) 

# With this map, you can zoom in and out to investigate points from a particular animal. You can also toggle on and off the various basemap tiles you have selected using the tile icon in the top left corner. If you plotted other data as well, you can also toggle these layers on and off. 

# Spend some time zooming into the map. You can see a large area in the central north of the study region with no locations. Once you zoom in you can see that this area is developed and that the wildebeest do not venture into this part of the landscape. There very well may be fencing excluding the herds from these areas as well. In the extreme north of the study area is the Kenyan capital Nairobi. This is more obvious when clicking on the street map basemap.

# Again here though, I do not see anything visually that would signal large positional errors. Let's dig into error a bit more in the next section.
```

# Summarize

